<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Hand Tracking AR Preview</title>
  <meta name="viewport" content="width=device-width,initial-scale=1.0">
  <!-- Google Model Viewer -->
  <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/4.0.0/model-viewer.min.js"></script>
  <style>
    body { 
      margin:0; 
      background:#181818; 
      font-family: 'Segoe UI',sans-serif; 
      overflow: hidden;
    }
    #handinfo {
      position: absolute; 
      top: 10px; 
      left: 10px; 
      z-index: 2;
      color: #fff; 
      background:rgba(30,30,66,0.85); 
      padding:12px; 
      border-radius:8px;
      font-size: 1rem;
    }
    #input-video { 
      width:0; 
      height:0; 
      position:absolute; 
    }
    canvas.overlay {
      position: fixed; 
      left:0; 
      top:0; 
      z-index:2; 
      pointer-events: none;
      width: 100vw; 
      height: 100vh;
    }
    #viewer {
      width: 100vw; 
      height: 100vh;
      display: none;
      position: fixed; 
      top:0; 
      left:0; 
      z-index:1;
      background: #181818;
    }
    #ar-button {
      position: absolute; 
      bottom:40px; 
      left: 50%; 
      transform: translateX(-50%);
      display: none;
      z-index:8;
      font-size: 1.2rem;
      padding: 16px 32px;
      background: linear-gradient(135deg,#667eea,#764ba2); 
      border:none;
      color:#fff; 
      border-radius:8px; 
      cursor:pointer; 
      box-shadow:0 2px 18px 0 rgba(0,0,0,0.35);
      transition: opacity 0.3s ease;
    }
    #ar-button:disabled {
      opacity: 0.6;
      cursor: not-allowed;
    }
    .loading {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      color: white;
      z-index: 3;
    }
  </style>
</head>
<body>
  <div id="handinfo">Initializing hand tracking...</div>
  <canvas class="overlay" id="overlay"></canvas>
  <video id="input-video" autoplay muted playsinline></video>
  
  <model-viewer
    id="viewer"
    src="./Diwali_crackers.glb"
    ios-src="./Diwali_crackers.usdz"
    ar
    ar-modes="webxr scene-viewer quick-look"
    ar-placement="floor"
    ar-scale="fixed"
    camera-controls
    tone-mapping="neutral"
    shadow-intensity="1"
    autoplay
    exposure="1"
    shadow-softness="0.5"
    style="display:none;"
  ></model-viewer>
  
  <button id="ar-button">View in AR</button>
  <div id="loading" class="loading" style="display: none;">Loading 3D model...</div>

  <script type="module">
    // MediaPipe Hand Tracking
    let HandLandmarker, FilesetResolver, handTracker;
    const info = document.getElementById('handinfo');
    const viewer = document.getElementById('viewer');
    const overlay = document.getElementById('overlay');
    const arButton = document.getElementById('ar-button');
    const loading = document.getElementById('loading');
    const ctx = overlay.getContext('2d');
    
    let camW = 640, camH = 480;
    let handFound = false;
    let isModelLoaded = false;
    let detectionActive = true;

    // Set canvas size to match window
    function setupCanvas() {
      overlay.width = window.innerWidth;
      overlay.height = window.innerHeight;
    }

    async function setupMediaPipe() {
      try {
        info.textContent = "Loading hand tracking model...";
        const vision = await import('https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.14/vision_bundle.js');
        HandLandmarker = vision.HandLandmarker;
        FilesetResolver = vision.FilesetResolver;
        
        const fileset = await FilesetResolver.forVisionTasks(
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.14/wasm'
        );
        
        handTracker = await HandLandmarker.createFromOptions(fileset, {
          baseOptions: { 
            modelAssetPath: 'https://storage.googleapis.com/mediapipe-assets/hand_landmarker.task',
            delegate: 'GPU'
          },
          runningMode: 'VIDEO',
          numHands: 1
        });
        
        info.textContent = "Hand tracking ready. Please allow camera access.";
      } catch (error) {
        console.error('Error setting up MediaPipe:', error);
        info.textContent = "Error loading hand tracking. Please refresh.";
      }
    }

    async function startCamera() {
      try {
        const video = document.getElementById('input-video');
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { 
            facingMode: 'environment', 
            width: { ideal: camW }, 
            height: { ideal: camH } 
          }, 
          audio: false 
        });
        
        video.srcObject = stream;
        
        return new Promise((resolve) => {
          video.onloadedmetadata = () => {
            video.play();
            camW = video.videoWidth;
            camH = video.videoHeight;
            setupCanvas();
            info.textContent = "Camera ready. Show your hand to the camera.";
            resolve(video);
          };
        });
      } catch (error) {
        console.error('Error accessing camera:', error);
        info.textContent = "Cannot access camera. Please check permissions.";
        throw error;
      }
    }

    function drawPalm(pts) {
      ctx.clearRect(0, 0, overlay.width, overlay.height);
      if (!pts || pts.length < 21) return;
      
      // Scale coordinates from camera space to screen space
      const scaleX = overlay.width / camW;
      const scaleY = overlay.height / camH;
      
      ctx.fillStyle = "rgba(52,255,114,0.92)";
      pts.forEach(p => {
        ctx.beginPath();
        ctx.arc(p.x * camW * scaleX, p.y * camH * scaleY, 6, 0, Math.PI * 2);
        ctx.fill();
      });
      
      // Calculate palm center
      let px = (pts[0].x + pts[5].x + pts[17].x)/3;
      let py = (pts[0].y + pts[5].y + pts[17].y)/3;
      
      ctx.beginPath();
      ctx.arc(px * camW * scaleX, py * camH * scaleY, 10, 0, Math.PI*2);
      ctx.fillStyle = "rgba(255,222,55,0.96)";
      ctx.fill();
    }

    function showARViewer() {
      if (!handFound) return;
      
      viewer.style.display = 'block';
      arButton.style.display = 'block';
      info.textContent = "Hand detected! Tap 'View in AR' to experience.";
    }

    function hideARViewer() {
      viewer.style.display = 'none';
      arButton.style.display = 'none';
      ctx.clearRect(0, 0, overlay.width, overlay.height);
      info.textContent = "Show your hand to the camera.";
    }

    async function detectHands(video) {
      if (!detectionActive) return;
      
      try {
        const res = await handTracker.detectForVideo(video, performance.now());
        
        if (res.landmarks && res.landmarks.length > 0) {
          const pts = res.landmarks[0];
          drawPalm(pts);
          
          if (!handFound) {
            handFound = true;
            showARViewer();
          }
        } else {
          if (handFound) {
            handFound = false;
            hideARViewer();
          }
        }
      } catch (error) {
        console.error('Detection error:', error);
      }
      
      if (detectionActive) {
        requestAnimationFrame(() => detectHands(video));
      }
    }

    // Model viewer event listeners
    function setupModelViewer() {
      viewer.addEventListener('load', () => {
        isModelLoaded = true;
        loading.style.display = 'none';
        arButton.disabled = false;
        console.log('3D model loaded successfully');
      });

      viewer.addEventListener('error', () => {
        loading.style.display = 'none';
        info.textContent = "Error loading 3D model. Check file paths.";
        arButton.disabled = true;
      });
    }

    // AR button handler
    function setupARButton() {
      arButton.addEventListener('click', async () => {
        if (!handFound || !isModelLoaded) return;
        
        try {
          await viewer.activateAR();
        } catch (error) {
          console.error('AR activation failed:', error);
          info.textContent = "AR not available on this device.";
        }
      });
    }

    // Handle window resize
    window.addEventListener('resize', setupCanvas);

    async function main() {
      try {
        await setupMediaPipe();
        const video = await startCamera();
        setupModelViewer();
        setupARButton();
        
        // Show loading for 3D model
        loading.style.display = 'block';
        arButton.disabled = true;
        
        // Start hand detection
        detectHands(video);
        
      } catch (error) {
        console.error('Main initialization failed:', error);
        info.textContent = "Failed to initialize application.";
      }
    }

    // Cleanup function
    function cleanup() {
      detectionActive = false;
      if (handTracker) {
        handTracker.close();
      }
      const video = document.getElementById('input-video');
      if (video && video.srcObject) {
        video.srcObject.getTracks().forEach(track => track.stop());
      }
    }

    // Handle page unload
    window.addEventListener('beforeunload', cleanup);

    // Start the application
    main();
  </script>
</body>
</html>
